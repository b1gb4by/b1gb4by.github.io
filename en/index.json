[{"categories":["kubernetes"],"content":"Let's take a deep dive into Karpenter.","date":"2021-12-27","objectID":"/en/2021/12/karpenter-deep-dive/","tags":["AWS","EKS","kubernetes","auto-scaling"],"title":"Karpenter Deep Dive","uri":"/en/2021/12/karpenter-deep-dive/"},{"categories":["kubernetes"],"content":"Recently, Karpenter graduated from AWS re:Invent with autoscaling of Nodes in Kubernetes clusters. In this article, we‚Äôll take a deeper look at it. ","date":"2021-12-27","objectID":"/en/2021/12/karpenter-deep-dive/:0:0","tags":["AWS","EKS","kubernetes","auto-scaling"],"title":"Karpenter Deep Dive","uri":"/en/2021/12/karpenter-deep-dive/"},{"categories":["kubernetes"],"content":"Introduction.This is the 18th day of the [Kubernetes Advent Calendar 2021](\u003c(https://qiita.com/advent-calendar/2021/kubernetes)). ","date":"2021-12-27","objectID":"/en/2021/12/karpenter-deep-dive/:1:0","tags":["AWS","EKS","kubernetes","auto-scaling"],"title":"Karpenter Deep Dive","uri":"/en/2021/12/karpenter-deep-dive/"},{"categories":["kubernetes"],"content":"What is Karpenter?Officially described as ‚ÄúJust-in-time Nodes for Any Kubernetes Cluster‚Äù, Karpenter provides the ability to instantly provision new Nodes for unscheduled Pods. The goal is to improve the efficiency and cost of running workloads on Kubernetes clusters. Karpenter works as follows. Monitor Pods that the Kubernetes scheduler has marked as unschedulable Evaluate the following scheduling constraints as requested by the Pod Resource Request Node Selector Affinity Tolerant Topology spreading constraints Provisioning a Node to meet Pod requirements Scheduling a Pod to run on a new Node Deleting a Node when it is no longer needed How to use Karpenter Karpenter will only support AWS as of December 2021. ","date":"2021-12-27","objectID":"/en/2021/12/karpenter-deep-dive/:2:0","tags":["AWS","EKS","kubernetes","auto-scaling"],"title":"Karpenter Deep Dive","uri":"/en/2021/12/karpenter-deep-dive/"},{"categories":["kubernetes"],"content":"Autoscale in KubernetesThere are two ways to scale the Pod. Horizontal Pod AutoscalerHorizontal pod scaling is a method of scaling to improve processing performance by increasing the number of pods. User-defined metrics such as CPU, memory, etc. can also be used to make decisions. The number of pods is calculated by the following formula. Number of replicas desired = ceil[\u003ccurrent number of pods\u003e * (\u003ccurrent index value / \u003ctarget index value\u003e)]. Vertical Pod AutoscalerThis is a method of scaling that improves processing performance by increasing the resources available to the pod. In this case, the CPU and memory are used as criteria. It is more like optimizing the resource utilization. ","date":"2021-12-27","objectID":"/en/2021/12/karpenter-deep-dive/:3:0","tags":["AWS","EKS","kubernetes","auto-scaling"],"title":"Karpenter Deep Dive","uri":"/en/2021/12/karpenter-deep-dive/"},{"categories":["kubernetes"],"content":"NodeCluster AutoscalerIt is a method of scaling to improve processing performance by increasing the number of worker Nodes. It can also be used in conjunction with horizontal scaling of Pods. ","date":"2021-12-27","objectID":"/en/2021/12/karpenter-deep-dive/:3:1","tags":["AWS","EKS","kubernetes","auto-scaling"],"title":"Karpenter Deep Dive","uri":"/en/2021/12/karpenter-deep-dive/"},{"categories":["kubernetes"],"content":"How to installKarpenter will be installed on the cluster with Helm Chart. Karpenter also requires IAM Roles for Service Accounts (IRSA). Currently, the utilities required to use Karpenter are as follows AWS CLI kubectl the Kubernetes CLI eksctl the CLI for AWS EKS helm the package manager for Kubernetes To learn how to install Karpenter on AWS, please refer to the official document ‚ÄúGetting Started with Karpenter on AWS‚Äù. Karpenter‚Äôs Helm Chart can be found here. Installation with Terraform Kapenter also provides an installation method using Terraform. See here for details. An overview diagram is shown in the figure below. ","date":"2021-12-27","objectID":"/en/2021/12/karpenter-deep-dive/:4:0","tags":["AWS","EKS","kubernetes","auto-scaling"],"title":"Karpenter Deep Dive","uri":"/en/2021/12/karpenter-deep-dive/"},{"categories":["kubernetes"],"content":"Configure the provisionerKarpenter‚Äôs job is to add Nodes that handle non-schedulable Pods, schedule Pods on those Nodes, and remove the Nodes when they are no longer needed. To configure Karpenter, create a provisioner that defines how Karpenter will manage non-schedulable Pods and timed Nodes. The following is what you need to know about Karpenter provisioners. ","date":"2021-12-27","objectID":"/en/2021/12/karpenter-deep-dive/:5:0","tags":["AWS","EKS","kubernetes","auto-scaling"],"title":"Karpenter Deep Dive","uri":"/en/2021/12/karpenter-deep-dive/"},{"categories":["kubernetes"],"content":"Unschedulable podsKarpenter will only attempt to provision Pods with the status condition Unschedulable=True. This will be set when the kube-scheduler fails to schedule a Pod to an existing capacity. ","date":"2021-12-27","objectID":"/en/2021/12/karpenter-deep-dive/:5:1","tags":["AWS","EKS","kubernetes","auto-scaling"],"title":"Karpenter Deep Dive","uri":"/en/2021/12/karpenter-deep-dive/"},{"categories":["kubernetes"],"content":"Provisioner CRKarpenter defines a custom resource called Provisioner to specify the provisioning configuration. Each provisioner manages a separate set of Nodes, but a Pod can be scheduled to any provisioner that supports its scheduling constraints. A provisioner contains constraints that affect the Nodes that can be provisioned and the attributes of the Nodes (such as timers for removing Nodes). The following are the resources of the provisioner. apiVersion:karpenter.sh/v1alpha5kind:Provisionermetadata:name:defaultspec:ttlSecondsUntilExpired:2592000ttlSecondsAfterEmpty:30taints:- key:example.com/special-tainteffect:NoSchedulelabels:billing-team:my-teamrequirements:- key:\"node.kubernetes.io/instance-type\"operator:Invalues:[\"m5.large\",\"m5.2xlarge\"]- key:\"topology.kubernetes.io/zone\"operator:Invalues:[\"us-west-2a\",\"us-west-2b\"]- key:\"kubernetes.io/arch\"operator:Invalues:[\"arm64\",\"amd64\"]- key:\"karpenter.sh/capacity-type\"operator:Invalues:[\"spot\",\"on-demand\"]provider:{} The spec.ttlSecondsUntilExpired is the number of seconds the controller will wait before exiting the Node, measured from the time the Node is created. This is useful to eventually implement features like consistent Node upgrades, memory leak protection, and destructive testing. If this field is not set, termination due to expiration will be disabled. The spec.ttlSecondsAfterEmpty is the number of seconds the controller will wait between the time it detects that a Node is empty and the time it tries to remove the Node. A Node is considered empty if there are no Pods scheduled for that Node, except for the daemonset. The spec.requirements constrains the parameters of the provisioned Node. It can be combined with nodeAffinity and nodeSelector. The { In, NotIn } operator is supported to include or exclude values. ","date":"2021-12-27","objectID":"/en/2021/12/karpenter-deep-dive/:5:2","tags":["AWS","EKS","kubernetes","auto-scaling"],"title":"Karpenter Deep Dive","uri":"/en/2021/12/karpenter-deep-dive/"},{"categories":["kubernetes"],"content":"Deprovisioning NodeKarpenter deletes the nodes that are no longer needed as follows. ","date":"2021-12-27","objectID":"/en/2021/12/karpenter-deep-dive/:6:0","tags":["AWS","EKS","kubernetes","auto-scaling"],"title":"Karpenter Deep Dive","uri":"/en/2021/12/karpenter-deep-dive/"},{"categories":["kubernetes"],"content":"FinalizerKarpenter will place a finalizer bit in each Node it creates. When a request to delete these Nodes comes in (such as a TTL or manual Node deletion via kubectl), Karpenter codes the Node, ejects all Pods, terminates the EC2 instance, and deletes the Node object. Karpenter handles all the cleanup work required to properly delete the Node. ","date":"2021-12-27","objectID":"/en/2021/12/karpenter-deep-dive/:6:1","tags":["AWS","EKS","kubernetes","auto-scaling"],"title":"Karpenter Deep Dive","uri":"/en/2021/12/karpenter-deep-dive/"},{"categories":["kubernetes"],"content":"Node ExpiryWhen a Node reaches its expiration value (ttlSecondsUntilExpired), it will be ejected and removed from the Pod (even if it is still running a workload). ","date":"2021-12-27","objectID":"/en/2021/12/karpenter-deep-dive/:6:2","tags":["AWS","EKS","kubernetes","auto-scaling"],"title":"Karpenter Deep Dive","uri":"/en/2021/12/karpenter-deep-dive/"},{"categories":["kubernetes"],"content":"Empty NodesWhen the last workload Pod running on a Karpenter-managed Node runs out, that Node will be given an emptiness timestamp. When its ‚ÄúNode is empty‚Äù expiration date (ttlSecondsAfterEmpty) is reached, finalization is triggered. About how to remove Node For more information on how Karpenter deletes Nodes, see Details on Node deprovisioning. ","date":"2021-12-27","objectID":"/en/2021/12/karpenter-deep-dive/:6:3","tags":["AWS","EKS","kubernetes","auto-scaling"],"title":"Karpenter Deep Dive","uri":"/en/2021/12/karpenter-deep-dive/"},{"categories":["kubernetes"],"content":"Upgrade NodeAn easy way to upgrade a Node is to set ttlSecondsUntilExpired, which will expire after a set period of time and be replaced by a newer Node. ","date":"2021-12-27","objectID":"/en/2021/12/karpenter-deep-dive/:7:0","tags":["AWS","EKS","kubernetes","auto-scaling"],"title":"Karpenter Deep Dive","uri":"/en/2021/12/karpenter-deep-dive/"},{"categories":["kubernetes"],"content":"ConstraintsBecause there are no constraints defined by the provisioner or requested by the Pod being deployed, Karpenter is selected from the entire set of features available from the cloud provider. Nodes can be created using any instance type and run in any zone. ","date":"2021-12-27","objectID":"/en/2021/12/karpenter-deep-dive/:8:0","tags":["AWS","EKS","kubernetes","auto-scaling"],"title":"Karpenter Deep Dive","uri":"/en/2021/12/karpenter-deep-dive/"},{"categories":["kubernetes"],"content":"SchedulingKarpenter schedules Pods that are marked as unschedulable by the Kubernetes scheduler. After resolving scheduling constraints and startup capacity, it creates a Node and binds the Pod. This stateless approach will help you avoid race conditions and improve performance. If there is a problem with a launched Node, Kubernetes will automatically migrate the Pod to a new Node. When Karpenter launches a Node, it will also allow Kubernetes' scheduler to schedule on it. ","date":"2021-12-27","objectID":"/en/2021/12/karpenter-deep-dive/:9:0","tags":["AWS","EKS","kubernetes","auto-scaling"],"title":"Karpenter Deep Dive","uri":"/en/2021/12/karpenter-deep-dive/"},{"categories":["kubernetes"],"content":"Cloud providerKarpenter makes a request to the relevant cloud provider for provisioning a new Node. The first supported cloud provider is AWS, but Karpenter is designed to work with other cloud providers as well. While using the well-known labels of Kubernetes, the provisioner can set a number of values specific to the cloud provider. If you are developing your own provider, you can create it in the repository under pkg/cloudprovider/. The directory structure is as follows. The fake directory is provided as an example for reference. . ‚îú‚îÄ‚îÄ aws ‚îÇ¬†‚îú‚îÄ‚îÄ apis ‚îÇ¬†‚îÇ¬†‚îî‚îÄ‚îÄ v1alpha1 ‚îÇ¬†‚îî‚îÄ‚îÄ fake ‚îú‚îÄ‚îÄ fake ‚îú‚îÄ‚îÄ metrics ‚îî‚îÄ‚îÄ registry First, you need to create the following files for each cloud provider under pkg/cloudprovider/registry to register them. // +build \u003cYOUR_PROVIDER_NAME\u003e import ( \"github.com/aws/karpenter/pkg/cloudprovider/\u003cYOUR_PROVIDER_NAME\u003e\" ) func NewCloudProvider() cloudprovider.CloudProvider { return \u003cYOUR_PROVIDER_NAME\u003e.NewCloudProvider() } You can also create one for each cloud provider under pkg/cloudprovider for your environment. If you check the fake directory, you will find the following files. You can add other necessary information according to your environment. . ‚îú‚îÄ‚îÄ cloudprovider.go ‚îî‚îÄ‚îÄ instancetype.go ","date":"2021-12-27","objectID":"/en/2021/12/karpenter-deep-dive/:10:0","tags":["AWS","EKS","kubernetes","auto-scaling"],"title":"Karpenter Deep Dive","uri":"/en/2021/12/karpenter-deep-dive/"},{"categories":["kubernetes"],"content":"Difference from Cluster AutoscalerLike Karpenter, the Kubernetes Cluster Autoscaler is designed to add Nodes when a request comes in to run a Pod that cannot be handled by the current capacity. Cluster Autoscaler is part of the Kubernetes project and is implemented by most of the major Kubernetes cloud providers. By rethinking provisioning, Karpenter provides the following improvements. ","date":"2021-12-27","objectID":"/en/2021/12/karpenter-deep-dive/:11:0","tags":["AWS","EKS","kubernetes","auto-scaling"],"title":"Karpenter Deep Dive","uri":"/en/2021/12/karpenter-deep-dive/"},{"categories":["kubernetes"],"content":"Designed to take advantage of the flexibility of the cloudKarpenter has the ability to efficiently handle any type of instance available in AWS. Cluster Autoscaler was not originally built with the flexibility to support hundreds of instance types, zones, and purchase options. ","date":"2021-12-27","objectID":"/en/2021/12/karpenter-deep-dive/:11:1","tags":["AWS","EKS","kubernetes","auto-scaling"],"title":"Karpenter Deep Dive","uri":"/en/2021/12/karpenter-deep-dive/"},{"categories":["kubernetes"],"content":"Groupless Node ProvisioningKarpenter manages each instance directly, without orchestration mechanisms such as Node groups. This allows you to retry in milliseconds instead of minutes if capacity is not available. It also allows you to take advantage of a variety of instance types, availability zones, and purchasing options without having to create hundreds of Node groups. ","date":"2021-12-27","objectID":"/en/2021/12/karpenter-deep-dive/:11:2","tags":["AWS","EKS","kubernetes","auto-scaling"],"title":"Karpenter Deep Dive","uri":"/en/2021/12/karpenter-deep-dive/"},{"categories":["kubernetes"],"content":"Scheduling ImplementationCluster Autoscaler does not bind a Pod to the Node it creates. Instead, it relies on the kube-scheduler to make the same scheduling decision after the Node comes online. The Node started by Karpenter is bound to its Pod immediately. kubelet does not need to wait for the scheduler or Node to be ready. kubelet does not need to wait for the scheduler or Node to be ready, it can start preparing the container runtime immediately, including pre-pulling images. This can reduce the Node startup latency by a few seconds. ","date":"2021-12-27","objectID":"/en/2021/12/karpenter-deep-dive/:11:3","tags":["AWS","EKS","kubernetes","auto-scaling"],"title":"Karpenter Deep Dive","uri":"/en/2021/12/karpenter-deep-dive/"},{"categories":["kubernetes"],"content":"ThoughtsIn this article, I‚Äôve tried to dig a little deeper into Karpenter. Personally, I think it‚Äôs the same as GKE Autopilot‚Äôs dynamic Node provisioning process. I think Karpenter is an OSS version of that tool. Like GKE Autopilot, Karpenter observes the specification of non-schedulable pods, computes aggregate resource requests, and sends the requests to an underlying compute service (such as Amazon EC2) that has the capacity required to run all the pods. Karpenter also allows you to define custom resources and specify the provisioning configuration for the following Nodes. We found the flexibility to change the configuration to be a significant advantage. Instance size/type, topology (zone, etc.) Architecture (arm64, amd64, etc.) Lifecycle type (spot, on-demand, pre-emptive, etc.) On the other hand, Karpenter can also deprovision a Node when it is no longer needed. This can be determined by setting the Node‚Äôs expiration date (ttlSecondsUntilExpired) or when the last workload running on a Karpenter provisioned Node has finished (ttlSecondsAfterEmpty). Either of these two events triggers a finalization that codes the Node, ejects the Pod, terminates the underlying compute resource, and deletes the Node object. This deprovisioning feature can also be used to keep Node up-to-date with the latest AMI. With Karpenter, I believe you can offload Node provisioning, autoscaling and upgrading and focus on running your application. Karpenter works with all kinds of Kubernetes applications, but I think it performs especially well in use cases where large amounts of diverse compute resources need to be provisioned and de-provisioned quickly. (Training machine learning models, running simulations, batch jobs with complex financial calculations, etc.) Currently, it only runs on AWS, but we will keep an eye on it in the future. If I have time, I‚Äôll try to implement it on other clouds as well. ","date":"2021-12-27","objectID":"/en/2021/12/karpenter-deep-dive/:12:0","tags":["AWS","EKS","kubernetes","auto-scaling"],"title":"Karpenter Deep Dive","uri":"/en/2021/12/karpenter-deep-dive/"},{"categories":["device"],"content":"Information about the device you have.","date":"2021-09-28","objectID":"/en/2021/09/device-configuration/","tags":["linux","mac","windows","device"],"title":"Device Configuration","uri":"/en/2021/09/device-configuration/"},{"categories":["device"],"content":"Describes detailed information about the devices you own. ","date":"2021-09-28","objectID":"/en/2021/09/device-configuration/:0:0","tags":["linux","mac","windows","device"],"title":"Device Configuration","uri":"/en/2021/09/device-configuration/"},{"categories":["device"],"content":"Macbook Pro (13-inch, 2019) Item Content OS macOS 12.0.1 (Monterey) 21A559 x86_64 CPU Intel i7-8569U (8) @ 2.80GHz GPU Intel Iris Plus Graphics 655 Memory 16 GB 2133 MHz LPDDR3 Terminal iTerm2 Terminal Font FiraCode Nerd Font Shell fish v3.3.1 ","date":"2021-09-28","objectID":"/en/2021/09/device-configuration/:1:0","tags":["linux","mac","windows","device"],"title":"Device Configuration","uri":"/en/2021/09/device-configuration/"},{"categories":["device"],"content":"Homebrew PCThere are two operating systems installed on your homebrew PC. ","date":"2021-09-28","objectID":"/en/2021/09/device-configuration/:2:0","tags":["linux","mac","windows","device"],"title":"Device Configuration","uri":"/en/2021/09/device-configuration/"},{"categories":["device"],"content":"Common Item Content Motherboard ROG STRIX H370-F GAMING (ASUSTeK COMPUTER INC.) CPU Intel(R) Core(TM) i5-8500 CPU @ 3.00GHz GPU NVIDIA GeForce GTX 1060 6GB (MSI Co., Ltd.) Memory DDR4-2666MHz 8√ó4GB (Corsair Inc.) Storage(OS) Crucial MX500 500√ó2GB (Micron Technology, Inc.) Storage Western Digital Blue: 6TB, Green: 3√ó2TB (Western Digital Corporation) ","date":"2021-09-28","objectID":"/en/2021/09/device-configuration/:2:1","tags":["linux","mac","windows","device"],"title":"Device Configuration","uri":"/en/2021/09/device-configuration/"},{"categories":["device"],"content":"OS (1) Item Content OS Windows 11 Pro (64bit) Terminal Windows Console Terminal Font FiraCode Shell PowerShell v7.1.4 ","date":"2021-09-28","objectID":"/en/2021/09/device-configuration/:2:2","tags":["linux","mac","windows","device"],"title":"Device Configuration","uri":"/en/2021/09/device-configuration/"},{"categories":["device"],"content":"OS (2) Item Content OS Manjaro Linux x86_64 Terminal xfce4-terminal Terminal Font FiraCode Nerd Font Shell bash 5.1.8 ","date":"2021-09-28","objectID":"/en/2021/09/device-configuration/:2:3","tags":["linux","mac","windows","device"],"title":"Device Configuration","uri":"/en/2021/09/device-configuration/"},{"categories":["device"],"content":"OS (3) Item Content OS MX x86_64 Terminal xfce4-terminal Terminal Font Lilex Nerd Font Mono Medium Shell zsh 5.8 ","date":"2021-09-28","objectID":"/en/2021/09/device-configuration/:2:4","tags":["linux","mac","windows","device"],"title":"Device Configuration","uri":"/en/2021/09/device-configuration/"},{"categories":null,"content":"morero's work history ","date":"2021-07-13","objectID":"/en/resume/","tags":null,"title":"Resume","uri":"/en/resume/"},{"categories":null,"content":"Personal Information key value Name Taisuke Okamoto Date of Birth 1996/12/02 ","date":"2021-07-13","objectID":"/en/resume/:1:0","tags":null,"title":"Resume","uri":"/en/resume/"},{"categories":null,"content":"Summary I‚Äôve been exposed to the Internet since I was 10 years old, and now I‚Äôm working as a backend engineer and SRE. Mainly used Golang to develop APIs and batches In infrastructure work, engaged in Kuberenetes monitoring, service meshing, and other tasks to increase availability. ","date":"2021-07-13","objectID":"/en/resume/:2:0","tags":null,"title":"Resume","uri":"/en/resume/"},{"categories":null,"content":"Languages and Technologies category technology stack Programing langage / Library etc‚Ä¶ Golang, Python, Java, PHP, C, Solidity, Zig(individual), gRPC Framework Gin, Falcon, Spring Boot Infrastructure GCP Middleware Redis Database MySQL, Cloud SQL Data analytics BigQuery Environment setup Ansible, Cloud Build. Docker, Terraform(individual) Container Orchestration Kubernetes, Rancher, CloudStack Monitoring Prometheus, Grafana Service Mesh Istio, Linkerd(individual) CI CircleCI, GitHub Actions ","date":"2021-07-13","objectID":"/en/resume/:3:0","tags":null,"title":"Resume","uri":"/en/resume/"},{"categories":null,"content":"Work Experience","date":"2021-07-13","objectID":"/en/resume/:4:0","tags":null,"title":"Resume","uri":"/en/resume/"},{"categories":null,"content":"IDC Frontier Inc. (2021/09 - Present)‚ë† Kubernetes as a Service (KaaS) development Project Size About 40 people (groups: 1 to 4) Roles Functional review, design, coding, other, surveys, research, etc. Project Details Development of an application that integrates Kubernetes as a Service with the company‚Äôs own cloud and other companies' cloud services Development of Kubernetes components for linking Kubernetes and the cloud, such as CSI Driver/Cloud Controller Manager/Ingress Controller Research and study of various Kubernetes features and implementations Research and study on various features and implementations of Kubernetes cluster management tools such as Rancher. Research, study, and development of various Cloud Native software/services required for Kubernetes as a Service. ","date":"2021-07-13","objectID":"/en/resume/:4:1","tags":null,"title":"Resume","uri":"/en/resume/"},{"categories":null,"content":"Papelook Co., Ltd. (2021/02 - 2021/08)‚ë† Development and operation of the company‚Äôs product order management system Project size Approximately 2~4 people Roles Tech lead, functional review, design, coding, review Project Details API development in Go language Operation of services completed within GCP Build CI/CD with CloudBuild + CloudRun and promote development speed Linkage with the EC platform (Shopify) used by the company ‚ë° Development and operation of systems for linking with Chinese and Korean EC sites, etc. Project size Individual Development Roles Functional review, design, coding Specification review and negotiation with alliances Project Details Implementation of API, batch processing, and webhook using Go language Batch processing uses concurrent processing to process 20,000~30,000 registrations per day. Linkage with Slack for early detection of errors Concurrently performs the following duties Development and maintenance of internal networks Construction, operation, and maintenance of client sites in the D2C business Automation of date and time reports for the company‚Äôs EC site using Google App Script and Google Analytics ","date":"2021-07-13","objectID":"/en/resume/:4:2","tags":null,"title":"Resume","uri":"/en/resume/"},{"categories":null,"content":"Video Market Co., Ltd. (2019/04 - 2021/01)‚ë† Renewal of the playback infrastructure within the distribution service Project size Approximately 20 people Role API functional study, design, coding, and review Design, coding, and review of cloud infrastructure Implementation of monitoring system Introduce vulnerability checking into CI/CD Project Details Replace the existing PHP regeneration infrastructure with Golang Microservices using GKE Reduce the cost of managing manifest environment differences in Kubernetes using Kustomize Secure communication between microservices by using service mesh Separate the usage and introduce suitable DBs such as BigQuery and Redis for each usage. Implement alerts using Grafana and Prometheus. Concurrently performs the following duties Performance Tuning of DRM ","date":"2021-07-13","objectID":"/en/resume/:4:3","tags":null,"title":"Resume","uri":"/en/resume/"},{"categories":null,"content":"Extra-curricular ActivitiesTechnical Coach / Relie inc. (2022/01 ~ Present) Role Conduct technical training Assist in solving engineering challenges Development of an integrated platform / Relie inc. (2021/07) Project size About 3 people Role API design, coding, development and review DB construction and migration automation Construction, operation, and maintenance of cloud servers Specification technology Golang GCP (GAE, CloudSQL, BigQuery) ","date":"2021-07-13","objectID":"/en/resume/:5:0","tags":null,"title":"Resume","uri":"/en/resume/"},{"categories":null,"content":"GiGs inc.","date":"2021-07-13","objectID":"/en/resume/:5:1","tags":null,"title":"Resume","uri":"/en/resume/"},{"categories":null,"content":"Development of voice platform (2019/07 - 2019/11) Project size Approximately 2 people Role. Design, implementation and testing of proprietary media playback player Specification Technologies HTML, CSS, JavaScript Supported part of the development of a service for a company started by a friend. ","date":"2021-07-13","objectID":"/en/resume/:5:2","tags":null,"title":"Resume","uri":"/en/resume/"},{"categories":null,"content":"Creating Landing Page (2017/10~2017/12) Project size Individual Development Role Building, operating, and maintaining WordPress Creation of LP site Specification technology WordPress, PHP, JavaScript, CSS, MySQL Created, published, and operated all LPs for a company started by a friend. ","date":"2021-07-13","objectID":"/en/resume/:5:3","tags":null,"title":"Resume","uri":"/en/resume/"},{"categories":null,"content":"Education Information Security Systems / Network Design (Old: Faculty of Information Science) / 2015-2019 - Osaka Institute of Technology ","date":"2021-07-13","objectID":"/en/resume/:6:0","tags":null,"title":"Resume","uri":"/en/resume/"},{"categories":null,"content":"Skills Certified Widevine Implementation Partner (Dec 2019) ","date":"2021-07-13","objectID":"/en/resume/:7:0","tags":null,"title":"Resume","uri":"/en/resume/"},{"categories":["music"],"content":"Introduce the Spofity playlist that you created.","date":"2021-06-08","objectID":"/en/2021/06/my-spotify-playlists/","tags":["spotify","playlist"],"title":"My Spotify Playlists","uri":"/en/2021/06/my-spotify-playlists/"},{"categories":["music"],"content":"The following playlists are currently being created. Please listen to it according to your TPO. playlist name genres Today in life is a collection of the past that I have always spent. House It eases my heart. House What‚Äôs up meeeeeen !? Dubstep, Bass The best part about me is I am not you. Hip-hop (Global) You can make something of your life. It just depends on your drive. Japanese Hip-hop Why don‚Äôt you sit and have something to drink? Lo-Fi Japanese Hip-hop Kawaii Kawaii Kawaiiiiiii Kawaii Bass I won‚Äôt be a rock star. I will be a legend. Rock ","date":"2021-06-08","objectID":"/en/2021/06/my-spotify-playlists/:0:0","tags":["spotify","playlist"],"title":"My Spotify Playlists","uri":"/en/2021/06/my-spotify-playlists/"},{"categories":["music"],"content":"1. Today in life is a collection of the past that I have always spent.The Royal Road to EDM. ","date":"2021-06-08","objectID":"/en/2021/06/my-spotify-playlists/:1:0","tags":["spotify","playlist"],"title":"My Spotify Playlists","uri":"/en/2021/06/my-spotify-playlists/"},{"categories":["music"],"content":"2. It eases my heart.No matter what situation you are in, you will be in a good mood. ","date":"2021-06-08","objectID":"/en/2021/06/my-spotify-playlists/:2:0","tags":["spotify","playlist"],"title":"My Spotify Playlists","uri":"/en/2021/06/my-spotify-playlists/"},{"categories":["music"],"content":"3. What‚Äôs up meeeeeen !?Helps to elevate moods and increase fighting spirit. ","date":"2021-06-08","objectID":"/en/2021/06/my-spotify-playlists/:3:0","tags":["spotify","playlist"],"title":"My Spotify Playlists","uri":"/en/2021/06/my-spotify-playlists/"},{"categories":["music"],"content":"4. The best part about me is I am not you.Try listening to the equalizer with the bass up, the midtones down, and the treble up a bit. ","date":"2021-06-08","objectID":"/en/2021/06/my-spotify-playlists/:4:0","tags":["spotify","playlist"],"title":"My Spotify Playlists","uri":"/en/2021/06/my-spotify-playlists/"},{"categories":["music"],"content":"5. You can make something of your life. It just depends on your drive.It covers the trends and niche of hip-hop in Japan. ","date":"2021-06-08","objectID":"/en/2021/06/my-spotify-playlists/:5:0","tags":["spotify","playlist"],"title":"My Spotify Playlists","uri":"/en/2021/06/my-spotify-playlists/"},{"categories":["music"],"content":"6. Why don‚Äôt you sit and have something to drink?It is good to listen to it when you want to calm down a little or when you are taking a break. ","date":"2021-06-08","objectID":"/en/2021/06/my-spotify-playlists/:6:0","tags":["spotify","playlist"],"title":"My Spotify Playlists","uri":"/en/2021/06/my-spotify-playlists/"},{"categories":["music"],"content":"7. Kawaii Kawaii KawaiiiiiiiThe fast tempo of the song will lift your spirits. ","date":"2021-06-08","objectID":"/en/2021/06/my-spotify-playlists/:7:0","tags":["spotify","playlist"],"title":"My Spotify Playlists","uri":"/en/2021/06/my-spotify-playlists/"},{"categories":["music"],"content":"8. I won‚Äôt be a rock star. I will be a legend.I can‚Äôt stop rock and roll. ","date":"2021-06-08","objectID":"/en/2021/06/my-spotify-playlists/:8:0","tags":["spotify","playlist"],"title":"My Spotify Playlists","uri":"/en/2021/06/my-spotify-playlists/"},{"categories":null,"content":"About morero profile","date":"2021-06-08","objectID":"/en/about/","tags":["profile","portfolio"],"title":"WHORU?","uri":"/en/about/"},{"categories":null,"content":"1. Who is morero?Hi, I‚Äôm Taisuke Okamoto. I‚Äôm a Software engineer living in Tokyoüóº. Recently, I‚Äôm mainly working on KaaS (Kuberentes As a Service) development. I like system optimization and network security. I sometimes play DJ as a hobby. ","date":"2021-06-08","objectID":"/en/about/:1:0","tags":["profile","portfolio"],"title":"WHORU?","uri":"/en/about/"},{"categories":null,"content":"2. About IconsCreated by South Park Avatar Creator ","date":"2021-06-08","objectID":"/en/about/:2:0","tags":["profile","portfolio"],"title":"WHORU?","uri":"/en/about/"}]